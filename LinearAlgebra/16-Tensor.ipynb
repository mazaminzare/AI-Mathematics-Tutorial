{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Algebra: An In-Depth Tutorial\n",
        "\n",
        "#### Mathematical Background\n",
        "\n",
        "Tensor algebra is a fundamental mathematical framework used in various fields such as physics, engineering, computer science, and machine learning. Tensors are generalizations of scalars, vectors, and matrices to higher dimensions.\n",
        "\n",
        "#### Key Concepts in Tensor Algebra\n",
        "\n",
        "1. **Scalars, Vectors, and Matrices**:\n",
        "    - **Scalars**: A single number, denoted by $a$.\n",
        "    - **Vectors**: A one-dimensional array of numbers, denoted by $\\mathbf{v} = [v_1, v_2, \\ldots, v_n]$.\n",
        "    - **Matrices**: A two-dimensional array of numbers, denoted by $\\mathbf{A} = [a_{ij}]$.\n",
        "\n",
        "2. **Tensors**:\n",
        "    - **Order**: The order (or rank) of a tensor is the number of dimensions (or modes). Scalars are 0th-order tensors, vectors are 1st-order tensors, and matrices are 2nd-order tensors.\n",
        "    - **Notation**: An $n$-th order tensor can be denoted by $\\mathcal{T}$, with elements $t_{i_1i_2\\ldots i_n}$.\n",
        "\n",
        "3. **Tensor Operations**:\n",
        "    - **Addition**: Tensors of the same shape can be added element-wise.\n",
        "    - **Multiplication**: There are several types of tensor multiplications, including the dot product, outer product, and tensor contraction.\n",
        "\n",
        "#### Tensor Operations\n",
        "\n",
        "1. **Addition**:\n",
        "\n",
        "Given two tensors $\\mathcal{A}$ and $\\mathcal{B}$ of the same shape, the addition is:\n",
        "\n",
        "$$\n",
        "\\mathcal{C} = \\mathcal{A} + \\mathcal{B}, \\quad \\text{where} \\quad c_{i_1i_2\\ldots i_n} = a_{i_1i_2\\ldots i_n} + b_{i_1i_2\\ldots i_n}\n",
        "$$\n",
        "\n",
        "2. **Multiplication**:\n",
        "\n",
        "- **Dot Product**:\n",
        "\n",
        "For vectors $\\mathbf{u}$ and $\\mathbf{v}$:\n",
        "\n",
        "$$\n",
        "\\mathbf{u} \\cdot \\mathbf{v} = \\sum_{i} u_i v_i\n",
        "$$\n",
        "\n",
        "- **Outer Product**:\n",
        "\n",
        "For vectors $\\mathbf{u}$ and $\\mathbf{v}$:\n",
        "\n",
        "$$\n",
        "\\mathcal{T} = \\mathbf{u} \\otimes \\mathbf{v}, \\quad \\text{where} \\quad t_{ij} = u_i v_j\n",
        "$$\n",
        "\n",
        "- **Tensor Contraction**:\n",
        "\n",
        "Tensor contraction generalizes matrix multiplication. For example, contracting two 3rd-order tensors $\\mathcal{A}$ and $\\mathcal{B}$ along the second dimension:\n",
        "\n",
        "$$\n",
        "\\mathcal{C}_{ijk} = \\sum_{l} a_{ilj} b_{lkj}\n",
        "$$\n",
        "\n",
        "#### Numerical Example\n",
        "\n",
        "Consider two 2nd-order tensors (matrices):\n",
        "\n",
        "$$\n",
        "\\mathbf{A} = \\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}, \\quad\n",
        "\\mathbf{B} = \\begin{bmatrix}\n",
        "5 & 6 \\\\\n",
        "7 & 8\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "1. **Addition**:\n",
        "\n",
        "$$\n",
        "\\mathbf{C} = \\mathbf{A} + \\mathbf{B} = \\begin{bmatrix}\n",
        "1 + 5 & 2 + 6 \\\\\n",
        "3 + 7 & 4 + 8\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "6 & 8 \\\\\n",
        "10 & 12\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "2. **Dot Product**:\n",
        "\n",
        "For vectors $\\mathbf{u} = [1, 2]$ and $\\mathbf{v} = [3, 4]$:\n",
        "\n",
        "$$\n",
        "\\mathbf{u} \\cdot \\mathbf{v} = 1 \\cdot 3 + 2 \\cdot 4 = 3 + 8 = 11\n",
        "$$\n",
        "\n",
        "3. **Outer Product**:\n",
        "\n",
        "For vectors $\\mathbf{u} = [1, 2]$ and $\\mathbf{v} = [3, 4]$:\n",
        "\n",
        "$$\n",
        "\\mathcal{T} = \\mathbf{u} \\otimes \\mathbf{v} = \\begin{bmatrix}\n",
        "1 \\cdot 3 & 1 \\cdot 4 \\\\\n",
        "2 \\cdot 3 & 2 \\cdot 4\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "3 & 4 \\\\\n",
        "6 & 8\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "4. **Tensor Contraction**:\n",
        "\n",
        "Consider two 3rd-order tensors $\\mathcal{A}$ and $\\mathcal{B}$:\n",
        "\n",
        "$$\n",
        "\\mathcal{A}_{ijk} = \\begin{bmatrix}\n",
        "\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix},\n",
        "\\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}\n",
        "\\end{bmatrix}, \\quad\n",
        "\\mathcal{B}_{ijk} = \\begin{bmatrix}\n",
        "\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix},\n",
        "\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Contracting along the second dimension:\n",
        "\n",
        "$$\n",
        "\\mathcal{C}_{ijk} = \\sum_{l} a_{ilj} b_{lkj}\n",
        "$$\n",
        "\n",
        "For simplicity, assuming $i=j=k=1$:\n",
        "\n",
        "$$\n",
        "\\mathcal{C}_{111} = \\sum_{l} a_{11l} b_{l11} = a_{111}b_{111} + a_{112}b_{211} = 1 \\cdot 1 + 2 \\cdot 1 = 3\n",
        "$$\n",
        "\n",
        "#### Key Properties of Tensor Algebra\n",
        "\n",
        "1. **Multilinearity**: Tensor operations are linear with respect to each argument. This property allows for generalization of linear operations to higher dimensions.\n",
        "\n",
        "2. **Dimensional Flexibility**: Tensors can represent data in multiple dimensions, which is useful in fields like machine learning, where data can be inherently multi-dimensional (e.g., images, videos).\n",
        "\n",
        "3. **Tensor Decompositions**: Tensors can be decomposed into simpler components (e.g., CANDECOMP/PARAFAC (CP) decomposition, Tucker decomposition), which is useful for data compression and feature extraction.\n",
        "\n",
        "4. **Generalization of Linear Algebra**: Tensor algebra extends concepts from linear algebra, such as matrix multiplication, to higher dimensions, enabling more complex and expressive mathematical modeling.\n",
        "\n",
        "#### Important Notes on Using Tensor Algebra\n",
        "\n",
        "- **Computational Complexity**: Operations on high-dimensional tensors can be computationally expensive. Efficient algorithms and parallel computing techniques are often required.\n",
        "\n",
        "- **Applications**: Tensors are widely used in various fields, including machine learning (tensor flow), physics (stress tensors, moment of inertia tensors), and computer graphics (transformation matrices).\n",
        "\n",
        "- **Software Libraries**: Libraries such as TensorFlow, PyTorch, and NumPy provide extensive support for tensor operations, making it easier to implement and optimize tensor algebra computations.\n",
        "\n",
        "This tutorial provides a comprehensive overview of tensor algebra, demonstrating its importance and application in various fields.\n"
      ],
      "metadata": {
        "id": "Y952gkO7iwv2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxqQLnBahRvM",
        "outputId": "e505b880-4226-4b93-87aa-9fc648d53520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Addition (A + B):\n",
            " [[ 6  8]\n",
            " [10 12]]\n",
            "\n",
            "Dot Product of Vectors (u . v): 11\n",
            "\n",
            "Outer Product of Vectors (u âŠ— v):\n",
            " [[3 4]\n",
            " [6 8]]\n",
            "\n",
            "Tensor Contraction Result:\n",
            " [[ 5  5]\n",
            " [13 13]]\n",
            "\n",
            "SVD of Matrix A:\n",
            "U:\n",
            " [[-0.40455358 -0.9145143 ]\n",
            " [-0.9145143   0.40455358]]\n",
            "Singular Values:\n",
            " [5.4649857  0.36596619]\n",
            "V:\n",
            " [[-0.57604844 -0.81741556]\n",
            " [ 0.81741556 -0.57604844]]\n"
          ]
        }
      ],
      "source": [
        "# Python Implementation of Tensor Algebra Operations\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define Scalars, Vectors, and Matrices\n",
        "scalar = 5\n",
        "vector_u = np.array([1, 2])\n",
        "vector_v = np.array([3, 4])\n",
        "matrix_A = np.array([[1, 2], [3, 4]])\n",
        "matrix_B = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Tensor Addition (Matrix Addition in this case)\n",
        "matrix_C = matrix_A + matrix_B\n",
        "print(\"Matrix Addition (A + B):\\n\", matrix_C)\n",
        "\n",
        "# Dot Product of Two Vectors\n",
        "dot_product = np.dot(vector_u, vector_v)\n",
        "print(\"\\nDot Product of Vectors (u . v):\", dot_product)\n",
        "\n",
        "# Outer Product of Two Vectors\n",
        "outer_product = np.outer(vector_u, vector_v)\n",
        "print(\"\\nOuter Product of Vectors (u âŠ— v):\\n\", outer_product)\n",
        "\n",
        "# Example of a 3rd-order Tensor\n",
        "tensor_A = np.array([\n",
        "    [[1, 2], [3, 4]],\n",
        "    [[5, 6], [7, 8]]\n",
        "])\n",
        "tensor_B = np.array([\n",
        "    [[1, 0], [0, 1]],\n",
        "    [[1, 0], [0, 1]]\n",
        "])\n",
        "\n",
        "# Tensor Contraction\n",
        "tensor_C = np.einsum('ijk,ljk->il', tensor_A, tensor_B)\n",
        "print(\"\\nTensor Contraction Result:\\n\", tensor_C)\n",
        "\n",
        "# Key Properties Demonstration\n",
        "# Multilinearity: Demonstrated through linear operations on tensors\n",
        "# Dimensional Flexibility: Representing and manipulating data in higher dimensions\n",
        "# Tensor Decompositions: Using SVD as a basic example (note: SVD is for 2nd-order tensors)\n",
        "\n",
        "# Singular Value Decomposition (SVD) Example\n",
        "U, S, V = np.linalg.svd(matrix_A)\n",
        "print(\"\\nSVD of Matrix A:\")\n",
        "print(\"U:\\n\", U)\n",
        "print(\"Singular Values:\\n\", S)\n",
        "print(\"V:\\n\", V)\n",
        "\n",
        "# Tensor Decomposition libraries can handle higher-order decompositions\n",
        "# e.g., Tensorly for CP decomposition, Tucker decomposition, etc.\n",
        "\n",
        "# Example using Tensorly library (if needed):\n",
        "# import tensorly as tl\n",
        "# from tensorly.decomposition import parafac, tucker\n",
        "\n",
        "# CP decomposition (PARAFAC)\n",
        "# cp_decomposition = parafac(tensor_A, rank=2)\n",
        "# print(\"\\nCP Decomposition:\\n\", cp_decomposition)\n",
        "\n",
        "# Tucker decomposition\n",
        "# tucker_decomposition = tucker(tensor_A, ranks=[2, 2, 2])\n",
        "# print(\"\\nTucker Decomposition:\\n\", tucker_decomposition)\n"
      ]
    }
  ]
}